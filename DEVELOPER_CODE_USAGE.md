# GeliÅŸtirici Kod KullanÄ±m Raporu

Bu dokÃ¼manda her geliÅŸtiricinin yazdÄ±ÄŸÄ± kodlarÄ±n projede nerede kullanÄ±ldÄ±ÄŸÄ± detaylÄ± olarak gÃ¶sterilmektedir.

---

## 1. HAKAN DEMÄ°RCAN - API Integration & Web Scraping

### DosyalarÄ±:
- `datasources/usgs_earthquake.py` - USGS deprem API'si
- `datasources/openweather_source.py` - OpenWeather hava durumu API'si
- `datasources/eonet_source.py` - NASA EONET genel API'si
- `datasources/eonet_wildfire_source.py` - EONET yangÄ±n verileri
- `datasources/eonet_storm_source.py` - EONET fÄ±rtÄ±na verileri
- `datasources/eonet_volcano_source.py` - EONET volkan verileri
- `datasources/flood_openmeteo_source.py` - OpenMeteo sel verileri
- `datasources/base_source.py` - TÃ¼m data source'larÄ±n base class'Ä±
- `datasources/scraping/scrape_news.py` - Haber scraping modÃ¼lÃ¼

### KullanÄ±m Yerleri:

#### 1.1 `main_runtime.py` (Ana Runtime Sistemi)
```python
# SatÄ±r 18-24: TÃ¼m Hakan'Ä±n data source'larÄ± import ediliyor
from datasources.usgs_earthquake import USGSEarthquakeSource
from datasources.openweather_source import OpenWeatherSource
from datasources.eonet_source import EONETSource
from datasources.eonet_wildfire_source import EONETWildfireSource
from datasources.eonet_storm_source import EONETStormSource
from datasources.eonet_volcano_source import EONETVolcanoSource
from datasources.flood_openmeteo_source import OpenMeteoFloodSource

# SatÄ±r 62: USGS Earthquake Source kullanÄ±lÄ±yor
earthquake_source = USGSEarthquakeSource(bbox=americas_bbox)

# SatÄ±r 69-94: 20 farklÄ± ÅŸehir iÃ§in OpenWeather Source'larÄ± oluÅŸturuluyor
weather_sources = [
    OpenWeatherSource(city="New York", country_code="US", include_forecast=True),
    # ... 19 ÅŸehir daha
]

# SatÄ±r 102: EONET Source kullanÄ±lÄ±yor
eonet_source = EONETSource(status="open", days=30, limit=100, bbox=americas_bbox)

# SatÄ±r 110: EONET Wildfire Source kullanÄ±lÄ±yor
wildfire_source = EONETWildfireSource(days=90, status="all", bbox=americas_bbox_str)

# SatÄ±r 115: EONET Storm Source kullanÄ±lÄ±yor
storm_source = EONETStormSource(days=60, status="all", bbox=americas_bbox_str)

# SatÄ±r 120: EONET Volcano Source kullanÄ±lÄ±yor
volcano_source = EONETVolcanoSource(days=90, status="all", bbox=americas_bbox_str)

# SatÄ±r 137-140: 10 ÅŸehir iÃ§in OpenMeteo Flood Source'larÄ± oluÅŸturuluyor
flood_sources = [
    OpenMeteoFloodSource(latitude=lat, longitude=lon, location_name=city, ...)
    for city, lat, lon in flood_cities
]

# SatÄ±r 147: TÃ¼m source'lar birleÅŸtiriliyor
all_sources = [earthquake_source] + weather_sources + [eonet_source] + ...
```

#### 1.2 `dashboard.py` (Web Dashboard)
```python
# SatÄ±r 16: News scraping modÃ¼lÃ¼ import ediliyor
from datasources.scraping.scrape_news import scrape_all_risk_headlines

# SatÄ±r 25: EONET Source import ediliyor
from datasources.eonet_source import EONETSource

# SatÄ±r 272: News scraping kullanÄ±lÄ±yor
news = scrape_all_risk_headlines()
```

#### 1.3 `pipeline/event_pipeline.py` (Event Processing)
```python
# SatÄ±r 37-43: Her data source iÃ§in processor tanÄ±mlanÄ±yor
self.processors = {
    'USGSEarthquakeSource': self._process_earthquake_events,
    'OpenWeatherSource': self._process_weather_events,
    'EONETSource': self._process_eonet_events,
    'EONETWildfireSource': self._process_wildfire_events,
    'EONETStormSource': self._process_storm_events,
    'EONETVolcanoSource': self._process_volcano_events,
    'OpenMeteoFloodSource': self._process_flood_events,
    ...
}
```

#### 1.4 `pipeline/fetch_wildfires.py` (YangÄ±n Verisi Ä°ÅŸleme)
```python
# SatÄ±r 11: EONET Wildfire Source import ediliyor
from datasources.eonet_wildfire_source import EONETWildfireSource

# SatÄ±r 51-52: Source kullanÄ±larak veri Ã§ekiliyor
raw = src.fetch_raw()
events = src.parse(raw)
```

#### 1.5 `pipeline/fetch_storms.py` (FÄ±rtÄ±na Verisi Ä°ÅŸleme)
```python
# SatÄ±r 11: EONET Storm Source import ediliyor
from datasources.eonet_storm_source import EONETStormSource

# SatÄ±r 181-182: Source kullanÄ±larak veri Ã§ekiliyor
raw = src.fetch_raw()
events = src.parse(raw)
```

#### 1.6 `pipeline/fetch_flood.py` (Sel Verisi Ä°ÅŸleme)
```python
# SatÄ±r 10: OpenMeteo Flood Source import ediliyor
from datasources.flood_openmeteo_source import OpenMeteoFloodSource

# SatÄ±r 51-52: Source kullanÄ±larak veri Ã§ekiliyor
raw = src.fetch_raw()
events = src.parse(raw)
```

#### 1.7 `pipeline/data_source_manager.py` (Data Source YÃ¶netimi)
```python
# SatÄ±r 12: Base Source import ediliyor
from datasources.base_source import DataSource

# TÃ¼m Hakan'Ä±n source'larÄ± DataSourceManager tarafÄ±ndan yÃ¶netiliyor
```

#### 1.8 `datasources/openweather_source.py` ve `usgs_earthquake.py`
```python
# Bu dosyalar iÃ§inde Erdem'in modelleri kullanÄ±lÄ±yor:
from models import Weather  # openweather_source.py
from models import RawEarthquake  # usgs_earthquake.py
```

---

## 2. ERDEM KAYA - Core System & Data Models

### DosyalarÄ±:
- `models/raw_earthquake.py` - Ham deprem verisi modeli
- `models/cleaned_earthquake.py` - TemizlenmiÅŸ deprem verisi modeli
- `models/earthquake.py` - Deprem modeli (RawEarthquake, CleanedEarthquake export)
- `models/weather.py` - Hava durumu modeli
- `models/natural_event.py` - DoÄŸal afet event modeli
- `models/__init__.py` - Model export'larÄ±

### KullanÄ±m Yerleri:

#### 2.1 `datasources/usgs_earthquake.py` (Hakan'Ä±n Kodu)
```python
# SatÄ±r 4: RawEarthquake modeli import ediliyor
from models import RawEarthquake

# SatÄ±r 40-50: USGS verileri RawEarthquake objelerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor
return RawEarthquake(
    id=usgs_id,
    magnitude=mag,
    location={"latitude": lat, "longitude": lon},
    timestamp=dt,
    ...
)
```

#### 2.2 `datasources/openweather_source.py` (Hakan'Ä±n Kodu)
```python
# SatÄ±r 6: Weather modeli import ediliyor
from models import Weather

# SatÄ±r 60-80: OpenWeather verileri Weather objelerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor
return Weather(
    city=city,
    country=country,
    temperature=temp,
    ...
)
```

#### 2.3 `processing/earthquake_processing.py` (Efe'nin Kodu)
```python
# SatÄ±r 3: Deprem modelleri import ediliyor
from models import RawEarthquake, CleanedEarthquake

# SatÄ±r 50-100: RawEarthquake objeleri CleanedEarthquake'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor
def clean_usgs_earthquake_events(raw_events):
    cleaned = []
    for raw in raw_events:
        if isinstance(raw, RawEarthquake):
            cleaned.append(CleanedEarthquake(...))
    return cleaned
```

#### 2.4 `pipeline/event_pipeline.py` (Fikret'in Kodu)
```python
# SatÄ±r 91: Weather modeli import ediliyor
from models import Weather

# SatÄ±r 49-79: RawEarthquake objeleri iÅŸleniyor
def _process_earthquake_events(self, events, source_name):
    cleaned_events = clean_usgs_earthquake_events(events)  # CleanedEarthquake dÃ¶ner
    ...
```

#### 2.5 `models/__init__.py` (Model Export'larÄ±)
```python
# TÃ¼m modeller buradan export ediliyor:
from .weather import Weather
from .earthquake import RawEarthquake, CleanedEarthquake
from .natural_event import NaturalEvent
```

---

## 3. YAÄIZ EFE HÃœÅAN - Data Processing & Analytics

### DosyalarÄ±:
- `processing/storage.py` - Veri saklama ve loglama
- `processing/earthquake_processing.py` - Veri temizleme ve dÃ¶nÃ¼ÅŸtÃ¼rme
- `processing/analytics.py` - Veri analizi ve istatistikler
- `pipeline/fetch_wildfires.py` - YangÄ±n verisi iÅŸleme
- `pipeline/fetch_storms.py` - FÄ±rtÄ±na verisi iÅŸleme
- `pipeline/fetch_flood.py` - Sel verisi iÅŸleme
- `datasources/eonet_wildfire_source.py` - EONET yangÄ±n source'u
- `datasources/eonet_storm_source.py` - EONET fÄ±rtÄ±na source'u
- `datasources/flood_openmeteo_source.py` - OpenMeteo sel source'u
- `datasources/eonet_volcano_source.py` - EONET volkan source'u

### KullanÄ±m Yerleri:

#### 3.1 `main_runtime.py` (Ana Runtime)
```python
# SatÄ±r 26: Storage modÃ¼lÃ¼nden log_message import ediliyor
from processing import log_message

# SatÄ±r 48, 56, 63, 95, 103, 111, 116, 121, 141, 144, 155, 161, 164, 171, 178:
# log_message fonksiyonu tÃ¼m sistem boyunca kullanÄ±lÄ±yor
log_message("SDEWS System Initialization", "INFO")
log_message("Data source'lar baslatiliyor...", "INFO")
# ... ve daha fazlasÄ±
```

#### 3.2 `pipeline/event_pipeline.py` (Event Processing)
```python
# SatÄ±r 12-17: Processing modÃ¼lleri import ediliyor
from processing import (
    log_message,
    clean_usgs_earthquake_events,  # Efe'nin earthquake_processing.py'den
    save_events_to_json,  # Efe'nin storage.py'den
    compute_basic_stats  # Efe'nin analytics.py'den
)

# SatÄ±r 53: clean_usgs_earthquake_events kullanÄ±lÄ±yor
cleaned_events = clean_usgs_earthquake_events(events)

# SatÄ±r 57: save_events_to_json kullanÄ±lÄ±yor
save_events_to_json(cleaned_events, filename)

# SatÄ±r 60-61: cleanup_old_files kullanÄ±lÄ±yor
from processing.storage import cleanup_old_files
cleanup_old_files()

# SatÄ±r 65: compute_basic_stats kullanÄ±lÄ±yor
stats = compute_basic_stats(stats_events)

# SatÄ±r 90: DATA_DIR kullanÄ±lÄ±yor
from processing.storage import DATA_DIR

# SatÄ±r 152: cleanup_old_files tekrar kullanÄ±lÄ±yor
from processing.storage import cleanup_old_files

# SatÄ±r 214: fetch_wildfires modÃ¼lÃ¼nden assign_city kullanÄ±lÄ±yor
from pipeline.fetch_wildfires import assign_city

# SatÄ±r 245: fetch_storms modÃ¼lÃ¼nden assign_city kullanÄ±lÄ±yor
from pipeline.fetch_storms import assign_city

# SatÄ±r 304: DATA_DIR tekrar kullanÄ±lÄ±yor
from processing.storage import DATA_DIR
```

#### 3.3 `dashboard.py` (Web Dashboard)
```python
# SatÄ±r 12: cleanup_old_files import ediliyor
from processing.storage import cleanup_old_files

# SatÄ±r 1233: cleanup_old_files kullanÄ±lÄ±yor (main block'ta)
if __name__ == '__main__':
    cleanup_old_files()
    app.run(debug=True, host='0.0.0.0', port=5000)
```

#### 3.4 `pipeline/fetch_wildfires.py` (Efe'nin Kendi DosyasÄ±)
```python
# SatÄ±r 11-12: Kendi modÃ¼llerini kullanÄ±yor
from datasources.eonet_wildfire_source import EONETWildfireSource
from processing.storage import log_message

# SatÄ±r 51-52: Source'dan veri Ã§ekiyor
raw = src.fetch_raw()
events = src.parse(raw)

# SatÄ±r 175-200: assign_city fonksiyonu tanÄ±mlanÄ±yor (event_pipeline.py tarafÄ±ndan kullanÄ±lÄ±yor)
def assign_city(lat, lon):
    # Åehir atama mantÄ±ÄŸÄ±
    ...
```

#### 3.5 `pipeline/fetch_storms.py` (Efe'nin Kendi DosyasÄ±)
```python
# SatÄ±r 11-12: Kendi modÃ¼llerini kullanÄ±yor
from datasources.eonet_storm_source import EONETStormSource
from processing.storage import log_message

# SatÄ±r 181-182: Source'dan veri Ã§ekiyor
raw = src.fetch_raw()
events = src.parse(raw)

# SatÄ±r 200-225: assign_city fonksiyonu tanÄ±mlanÄ±yor (event_pipeline.py tarafÄ±ndan kullanÄ±lÄ±yor)
def assign_city(lat, lon):
    # Åehir atama mantÄ±ÄŸÄ±
    ...
```

#### 3.6 `pipeline/fetch_flood.py` (Efe'nin Kendi DosyasÄ±)
```python
# SatÄ±r 10-11: Kendi modÃ¼llerini kullanÄ±yor
from datasources.flood_openmeteo_source import OpenMeteoFloodSource
from processing.storage import log_message

# SatÄ±r 51-52: Source'dan veri Ã§ekiyor
raw = src.fetch_raw()
events = src.parse(raw)
```

#### 3.7 `processing/earthquake_processing.py` (Efe'nin Kendi DosyasÄ±)
```python
# SatÄ±r 2: Kendi storage modÃ¼lÃ¼nÃ¼ kullanÄ±yor
from .storage import log_message

# SatÄ±r 3: Erdem'in modellerini kullanÄ±yor
from models import RawEarthquake, CleanedEarthquake

# SatÄ±r 50-100: clean_usgs_earthquake_events fonksiyonu
# event_pipeline.py tarafÄ±ndan kullanÄ±lÄ±yor
def clean_usgs_earthquake_events(raw_events):
    ...
```

#### 3.8 `processing/storage.py` (Efe'nin Kendi DosyasÄ±)
```python
# Bu dosya tÃ¼m projede kullanÄ±lÄ±yor:
# - log_message() fonksiyonu
# - save_events_to_json() fonksiyonu
# - cleanup_old_files() fonksiyonu
# - DATA_DIR constant'Ä±
```

#### 3.9 `processing/analytics.py` (Efe'nin Kendi DosyasÄ±)
```python
# compute_basic_stats fonksiyonu event_pipeline.py tarafÄ±ndan kullanÄ±lÄ±yor
def compute_basic_stats(events):
    # Ä°statistik hesaplamalarÄ±
    ...
```

---

## 4. FÄ°KRET AHISKALI - Concurrency & Runtime Pipeline

### DosyalarÄ±:
- `pipeline/runtime_system.py` - Ana runtime sistemi
- `pipeline/data_source_manager.py` - Data source yÃ¶netimi (concurrent fetching)
- `pipeline/event_pipeline.py` - Event processing pipeline (Producer-Consumer pattern)
- `main_runtime.py` - Ana entry point (tÃ¼m sistemi birleÅŸtiriyor)

### KullanÄ±m Yerleri:

#### 4.1 `main_runtime.py` (Fikret'in Kendi DosyasÄ±)
```python
# SatÄ±r 25: Kendi RuntimeSystem'ini import ediyor
from pipeline import RuntimeSystem

# SatÄ±r 149-153: RuntimeSystem oluÅŸturuluyor
runtime = RuntimeSystem(
    data_sources=all_sources,  # Hakan'Ä±n source'larÄ±
    fetch_interval=120,
    num_consumers=5
)

# SatÄ±r 168: Runtime sistemi baÅŸlatÄ±lÄ±yor
runtime.start(continuous=continuous)

# SatÄ±r 178: Runtime sistemi durduruluyor
runtime.stop()
```

#### 4.2 `pipeline/runtime_system.py` (Fikret'in Kendi DosyasÄ±)
```python
# SatÄ±r 13-14: Kendi modÃ¼llerini kullanÄ±yor
from .data_source_manager import DataSourceManager
from .event_pipeline import EventPipeline

# SatÄ±r 12: Hakan'Ä±n base_source'unu kullanÄ±yor
from datasources.base_source import DataSource

# RuntimeSystem, DataSourceManager ve EventPipeline'Ä± koordine ediyor
```

#### 4.3 `pipeline/data_source_manager.py` (Fikret'in Kendi DosyasÄ±)
```python
# SatÄ±r 12: Hakan'Ä±n base_source'unu kullanÄ±yor
from datasources.base_source import DataSource

# DataSourceManager, tÃ¼m Hakan'Ä±n source'larÄ±nÄ± concurrent olarak yÃ¶netiyor
# Threading kullanarak paralel veri Ã§ekme iÅŸlemi yapÄ±yor
```

#### 4.4 `pipeline/event_pipeline.py` (Fikret'in Kendi DosyasÄ±)
```python
# SatÄ±r 12-17: Efe'nin processing modÃ¼llerini kullanÄ±yor
from processing import (
    log_message,
    clean_usgs_earthquake_events,
    save_events_to_json,
    compute_basic_stats
)

# SatÄ±r 91: Erdem'in Weather modelini kullanÄ±yor
from models import Weather

# SatÄ±r 214: Efe'nin fetch_wildfires modÃ¼lÃ¼nÃ¼ kullanÄ±yor
from pipeline.fetch_wildfires import assign_city

# SatÄ±r 245: Efe'nin fetch_storms modÃ¼lÃ¼nÃ¼ kullanÄ±yor
from pipeline.fetch_storms import assign_city

# EventPipeline, Producer-Consumer pattern ile event'leri iÅŸliyor
# Her data source tipi iÃ§in Ã¶zel processor fonksiyonlarÄ± var
```

#### 4.5 `pipeline/__init__.py` (Fikret'in Export DosyasÄ±)
```python
# SatÄ±r 6-8: TÃ¼m pipeline modÃ¼lleri export ediliyor
from .data_source_manager import DataSourceManager
from .event_pipeline import EventPipeline
from .runtime_system import RuntimeSystem
```

#### 4.6 `test_runtime.py` (Test DosyasÄ±)
```python
# SatÄ±r 11: Fikret'in pipeline modÃ¼llerini test ediyor
from pipeline import DataSourceManager, EventPipeline, RuntimeSystem
```

---

## Ã–ZET: Kod BaÄŸÄ±mlÄ±lÄ±klarÄ±

### Hakan'Ä±n KodlarÄ±:
- âœ… **KullanÄ±lÄ±yor**: TÃ¼m data source'lar (`main_runtime.py`, `dashboard.py`, `pipeline/` modÃ¼lleri)
- âœ… **BaÄŸÄ±mlÄ±lÄ±k**: Erdem'in `models/` modÃ¼llerini kullanÄ±yor
- âœ… **KullanÄ±cÄ±lar**: Fikret (pipeline), Efe (fetch modÃ¼lleri), Dashboard

### Erdem'in KodlarÄ±:
- âœ… **KullanÄ±lÄ±yor**: TÃ¼m model sÄ±nÄ±flarÄ± (`datasources/`, `processing/`, `pipeline/`)
- âœ… **BaÄŸÄ±mlÄ±lÄ±k**: Yok (base modeller)
- âœ… **KullanÄ±cÄ±lar**: Hakan (data source'lar), Efe (data processing), Fikret (event pipeline)

### Efe'nin KodlarÄ±:
- âœ… **KullanÄ±lÄ±yor**: TÃ¼m processing modÃ¼lleri (`pipeline/event_pipeline.py`, `dashboard.py`)
- âœ… **BaÄŸÄ±mlÄ±lÄ±k**: Erdem'in `models/` modÃ¼llerini kullanÄ±yor
- âœ… **KullanÄ±cÄ±lar**: Fikret (event pipeline), Dashboard

### Fikret'in KodlarÄ±:
- âœ… **KullanÄ±lÄ±yor**: Ana runtime sistemi (`main_runtime.py`)
- âœ… **BaÄŸÄ±mlÄ±lÄ±k**: Hakan'Ä±n `datasources/`, Efe'nin `processing/`, Erdem'in `models/`
- âœ… **KullanÄ±cÄ±lar**: Ana sistem entry point

---

## SONUÃ‡

**TÃ¼m geliÅŸtiricilerin kodlarÄ± aktif olarak kullanÄ±lÄ±yor!**

- **Hakan**: API entegrasyonlarÄ± ve data source'lar â†’ Ana runtime ve dashboard'da kullanÄ±lÄ±yor
- **Erdem**: Data modelleri â†’ TÃ¼m sistemde kullanÄ±lÄ±yor (Hakan, Efe, Fikret)
- **Efe**: Data processing ve analytics â†’ Pipeline ve dashboard'da kullanÄ±lÄ±yor
- **Fikret**: Runtime pipeline ve concurrency â†’ Ana sistem koordinasyonu

Herkesin branch'inden Ã§ekilen kodlar entegre edilmiÅŸ ve aktif olarak Ã§alÄ±ÅŸÄ±yor! ğŸ‰

